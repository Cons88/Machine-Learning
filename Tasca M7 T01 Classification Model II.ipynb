{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3ab77e4",
   "metadata": {},
   "source": [
    "**Tasca M7 T01**\n",
    "\n",
    "**Exercicis d'algoritmes de Classificació**\n",
    "\n",
    "- Exercici 1 Crea almenys dos models de classificació diferents per intentar predir el millor les classes de l'arxiu adjunt.\n",
    "\n",
    "\n",
    "- Exercici 2 Compara els models de classificació utilitzant la precisió (accuracy), una matriu de confusió i d’altres mètriques més avançades.\n",
    "\n",
    "\n",
    "- Exercici 3\n",
    "Entrena’ls usant els diferents paràmetres que admeten per tal de millorar-ne la predicció.\n",
    "\n",
    "\n",
    "- Exercici 4\n",
    "Compara el seu rendiment fent servir l’aproximació traint/test o cross-validation.\n",
    "\n",
    "\n",
    "- Exercici 5\n",
    "Aplica algun procés d'enginyeria per millorar els resultats (normalització, estandardització, mostreig...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3175203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b99c0758",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_table('wineData.txt', sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "664b71db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>14.23</th>\n",
       "      <th>1.71</th>\n",
       "      <th>2.43</th>\n",
       "      <th>15.6</th>\n",
       "      <th>127</th>\n",
       "      <th>2.8</th>\n",
       "      <th>3.06</th>\n",
       "      <th>.28</th>\n",
       "      <th>2.29</th>\n",
       "      <th>5.64</th>\n",
       "      <th>1.04</th>\n",
       "      <th>3.92</th>\n",
       "      <th>1065</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>14.20</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.45</td>\n",
       "      <td>15.2</td>\n",
       "      <td>112</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.75</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>3</td>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>3</td>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>3</td>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>3</td>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>3</td>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1  14.23  1.71  2.43  15.6  127   2.8  3.06   .28  2.29   5.64  1.04  \\\n",
       "0    1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28   4.38  1.05   \n",
       "1    1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81   5.68  1.03   \n",
       "2    1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18   7.80  0.86   \n",
       "3    1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82   4.32  1.04   \n",
       "4    1  14.20  1.76  2.45  15.2  112  3.27  3.39  0.34  1.97   6.75  1.05   \n",
       "..  ..    ...   ...   ...   ...  ...   ...   ...   ...   ...    ...   ...   \n",
       "172  3  13.71  5.65  2.45  20.5   95  1.68  0.61  0.52  1.06   7.70  0.64   \n",
       "173  3  13.40  3.91  2.48  23.0  102  1.80  0.75  0.43  1.41   7.30  0.70   \n",
       "174  3  13.27  4.28  2.26  20.0  120  1.59  0.69  0.43  1.35  10.20  0.59   \n",
       "175  3  13.17  2.59  2.37  20.0  120  1.65  0.68  0.53  1.46   9.30  0.60   \n",
       "176  3  14.13  4.10  2.74  24.5   96  2.05  0.76  0.56  1.35   9.20  0.61   \n",
       "\n",
       "     3.92  1065  \n",
       "0    3.40  1050  \n",
       "1    3.17  1185  \n",
       "2    3.45  1480  \n",
       "3    2.93   735  \n",
       "4    2.85  1450  \n",
       "..    ...   ...  \n",
       "172  1.74   740  \n",
       "173  1.56   750  \n",
       "174  1.56   835  \n",
       "175  1.62   840  \n",
       "176  1.60   560  \n",
       "\n",
       "[177 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73ccf9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = [['Class identifier', 'Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', \n",
    "'Magnesium','Total phenols', 'Flavanoids', 'Nonflavanoid phenols','Proanthocyanins', 'Color intensity', 'Hue', 'OD280/OD315 of diluted wines', 'Proline ']]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "093dcf66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Class identifier</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>14.20</td>\n",
       "      <td>1.76</td>\n",
       "      <td>2.45</td>\n",
       "      <td>15.2</td>\n",
       "      <td>112</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.97</td>\n",
       "      <td>6.75</td>\n",
       "      <td>1.05</td>\n",
       "      <td>2.85</td>\n",
       "      <td>1450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>3</td>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>3</td>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>3</td>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>3</td>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>3</td>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Class identifier Alcohol Malic acid   Ash Alcalinity of ash Magnesium  \\\n",
       "0                  1   13.20       1.78  2.14              11.2       100   \n",
       "1                  1   13.16       2.36  2.67              18.6       101   \n",
       "2                  1   14.37       1.95  2.50              16.8       113   \n",
       "3                  1   13.24       2.59  2.87              21.0       118   \n",
       "4                  1   14.20       1.76  2.45              15.2       112   \n",
       "..               ...     ...        ...   ...               ...       ...   \n",
       "172                3   13.71       5.65  2.45              20.5        95   \n",
       "173                3   13.40       3.91  2.48              23.0       102   \n",
       "174                3   13.27       4.28  2.26              20.0       120   \n",
       "175                3   13.17       2.59  2.37              20.0       120   \n",
       "176                3   14.13       4.10  2.74              24.5        96   \n",
       "\n",
       "    Total phenols Flavanoids Nonflavanoid phenols Proanthocyanins  \\\n",
       "0            2.65       2.76                 0.26            1.28   \n",
       "1            2.80       3.24                 0.30            2.81   \n",
       "2            3.85       3.49                 0.24            2.18   \n",
       "3            2.80       2.69                 0.39            1.82   \n",
       "4            3.27       3.39                 0.34            1.97   \n",
       "..            ...        ...                  ...             ...   \n",
       "172          1.68       0.61                 0.52            1.06   \n",
       "173          1.80       0.75                 0.43            1.41   \n",
       "174          1.59       0.69                 0.43            1.35   \n",
       "175          1.65       0.68                 0.53            1.46   \n",
       "176          2.05       0.76                 0.56            1.35   \n",
       "\n",
       "    Color intensity   Hue OD280/OD315 of diluted wines Proline   \n",
       "0              4.38  1.05                         3.40     1050  \n",
       "1              5.68  1.03                         3.17     1185  \n",
       "2              7.80  0.86                         3.45     1480  \n",
       "3              4.32  1.04                         2.93      735  \n",
       "4              6.75  1.05                         2.85     1450  \n",
       "..              ...   ...                          ...      ...  \n",
       "172            7.70  0.64                         1.74      740  \n",
       "173            7.30  0.70                         1.56      750  \n",
       "174           10.20  0.59                         1.56      835  \n",
       "175            9.30  0.60                         1.62      840  \n",
       "176            9.20  0.61                         1.60      560  \n",
       "\n",
       "[177 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b17cfd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Class identifier</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.943503</td>\n",
       "      <td>12.993672</td>\n",
       "      <td>2.339887</td>\n",
       "      <td>2.366158</td>\n",
       "      <td>19.516949</td>\n",
       "      <td>99.587571</td>\n",
       "      <td>2.292260</td>\n",
       "      <td>2.023446</td>\n",
       "      <td>0.362316</td>\n",
       "      <td>1.586949</td>\n",
       "      <td>5.054802</td>\n",
       "      <td>0.956983</td>\n",
       "      <td>2.604294</td>\n",
       "      <td>745.096045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.773991</td>\n",
       "      <td>0.808808</td>\n",
       "      <td>1.119314</td>\n",
       "      <td>0.275080</td>\n",
       "      <td>3.336071</td>\n",
       "      <td>14.174018</td>\n",
       "      <td>0.626465</td>\n",
       "      <td>0.998658</td>\n",
       "      <td>0.124653</td>\n",
       "      <td>0.571545</td>\n",
       "      <td>2.324446</td>\n",
       "      <td>0.229135</td>\n",
       "      <td>0.705103</td>\n",
       "      <td>314.884046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.360000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.740000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.210000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>1.930000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.870000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.350000</td>\n",
       "      <td>2.130000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.550000</td>\n",
       "      <td>4.680000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>672.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>13.670000</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>2.560000</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.860000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>985.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Class identifier     Alcohol  Malic acid         Ash Alcalinity of ash  \\\n",
       "count       177.000000  177.000000  177.000000  177.000000        177.000000   \n",
       "mean          1.943503   12.993672    2.339887    2.366158         19.516949   \n",
       "std           0.773991    0.808808    1.119314    0.275080          3.336071   \n",
       "min           1.000000   11.030000    0.740000    1.360000         10.600000   \n",
       "25%           1.000000   12.360000    1.600000    2.210000         17.200000   \n",
       "50%           2.000000   13.050000    1.870000    2.360000         19.500000   \n",
       "75%           3.000000   13.670000    3.100000    2.560000         21.500000   \n",
       "max           3.000000   14.830000    5.800000    3.230000         30.000000   \n",
       "\n",
       "        Magnesium Total phenols  Flavanoids Nonflavanoid phenols  \\\n",
       "count  177.000000    177.000000  177.000000           177.000000   \n",
       "mean    99.587571      2.292260    2.023446             0.362316   \n",
       "std     14.174018      0.626465    0.998658             0.124653   \n",
       "min     70.000000      0.980000    0.340000             0.130000   \n",
       "25%     88.000000      1.740000    1.200000             0.270000   \n",
       "50%     98.000000      2.350000    2.130000             0.340000   \n",
       "75%    107.000000      2.800000    2.860000             0.440000   \n",
       "max    162.000000      3.880000    5.080000             0.660000   \n",
       "\n",
       "      Proanthocyanins Color intensity         Hue  \\\n",
       "count      177.000000      177.000000  177.000000   \n",
       "mean         1.586949        5.054802    0.956983   \n",
       "std          0.571545        2.324446    0.229135   \n",
       "min          0.410000        1.280000    0.480000   \n",
       "25%          1.250000        3.210000    0.780000   \n",
       "50%          1.550000        4.680000    0.960000   \n",
       "75%          1.950000        6.200000    1.120000   \n",
       "max          3.580000       13.000000    1.710000   \n",
       "\n",
       "      OD280/OD315 of diluted wines     Proline   \n",
       "count                   177.000000   177.000000  \n",
       "mean                      2.604294   745.096045  \n",
       "std                       0.705103   314.884046  \n",
       "min                       1.270000   278.000000  \n",
       "25%                       1.930000   500.000000  \n",
       "50%                       2.780000   672.000000  \n",
       "75%                       3.170000   985.000000  \n",
       "max                       4.000000  1680.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f832b466",
   "metadata": {},
   "source": [
    "- We can split our dataset into its attributes and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c019545",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flore\\AppData\\Local\\Temp\\ipykernel_38872\\2905116668.py:2: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  X = data.drop(['Class identifier'], axis = 1) # Features\n"
     ]
    }
   ],
   "source": [
    "y = data['Class identifier'] # Label \n",
    "X = data.drop(['Class identifier'], axis = 1) # Features "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1267a53b",
   "metadata": {},
   "source": [
    "- **Splitting Data into Train and Test Sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fa66c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6cae9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 13)\n",
      "(132, 1)\n",
      "(45, 13)\n",
      "(45, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d233f9",
   "metadata": {},
   "source": [
    "- **Feature Scaling for Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "819dce35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flore\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\flore\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n",
      "C:\\Users\\flore\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1688: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: ['tuple']. An error will be raised in 1.2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99dacba",
   "metadata": {},
   "source": [
    "- **Model for Classsification: Support Vector Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44ad0814",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flore\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c42b736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results:\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "401925b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3, 1, 3, 1, 2, 3, 2, 3, 1, 3, 1, 2, 1, 2, 2, 3, 1, 2, 1, 2,\n",
       "       3, 3, 3, 3, 3, 2, 2, 1, 1, 2, 3, 1, 1, 1, 3, 3, 2, 3, 1, 2, 2, 2,\n",
       "       3], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0869b527",
   "metadata": {},
   "source": [
    "- **Making the Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86e8095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6aa3bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        15\n",
      "           2       1.00      0.78      0.88        18\n",
      "           3       0.75      1.00      0.86        12\n",
      "\n",
      "    accuracy                           0.91        45\n",
      "   macro avg       0.92      0.93      0.91        45\n",
      "weighted avg       0.93      0.91      0.91        45\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "#importing Seaborn's to use the heatmap \n",
    "import seaborn as sns\n",
    "\n",
    "# Adding classes names for better interpretation\n",
    "classes_names = ['class 1','class 2','class 3']\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, y_pred), \n",
    "                  columns=classes_names, index = classes_names)\n",
    "                  \n",
    "# Seaborn's heatmap to better visualize the confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d');\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3a4dc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "676cb5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9111111111111111"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ecd741",
   "metadata": {},
   "source": [
    "- **Applying Grid Search to find the best model and the best parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b42d72b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flore\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'C': [1, 10, 100, 1000], 'kernel' : ['linear']}, \n",
    "             {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\n",
    "\n",
    "grid_search = GridSearchCV(estimator = classifier, \n",
    "                          param_grid = parameters, \n",
    "                          scoring = 'accuracy', \n",
    "                          cv = 10, \n",
    "                          n_jobs = -1)\n",
    "\n",
    "grid_search = grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a4fff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a654a315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9851648351648352"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10a47831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed93b3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flore\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73f0c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results:\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0d2c3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6f671246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9d6aecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9111111111111111"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db852778",
   "metadata": {},
   "source": [
    "- Changing Kernel Parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87f98dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\flore\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(random_state=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "classifier = SVC(kernel = 'rbf', random_state = 0)\n",
    "\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c918aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results:\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b985e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "720a6dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b02020b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy # I don´t undertand why best paramenters are shown as: {'C': 1, 'kernel': 'linear'} result for grid_search.best_params_ \n",
    "# when I write, however, 'rbf' for Kernel the result in accuracy is higher..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
